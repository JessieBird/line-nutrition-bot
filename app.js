import express from 'express';
import { config } from 'dotenv';
import { middleware, Client } from '@line/bot-sdk';
import { OpenAI } from 'openai';

config();

const app = express();
const port = process.env.PORT || 3000;

// è¨­å®š LINE SDK
const lineConfig = {
  channelAccessToken: process.env.LINE_CHANNEL_ACCESS_TOKEN,
  channelSecret: process.env.LINE_CHANNEL_SECRET,
};

const lineClient = new Client(lineConfig);

// è¨­å®š OpenAI SDK
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

app.post('/callback', middleware(lineConfig), async (req, res) => {
  try {
    const events = req.body.events;
    const results = await Promise.all(events.map(handleEvent));
    res.status(200).json(results);
  } catch (err) {
    console.error('âŒ Webhook è™•ç†éŒ¯èª¤:', err);
    res.status(500).end();
  }
});

async function handleEvent(event) {
  if (event.type !== 'message' || event.message.type !== 'text') {
    return Promise.resolve(null);
  }

  const userInput = event.message.text;

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'user',
          content: `è«‹ä½ æ ¹æ“šã€Œ${userInput}ã€é€™ç¨®é£Ÿç‰©ï¼Œå›è¦†æ ¼å¼å¦‚ä¸‹ï¼Œä¸è¦å¤šåŠ èªªæ˜ï¼š

é£Ÿç‰©ï¼šxxx  
ç†±é‡ï¼šç´„ xxx å¤§å¡ / 100g  
è›‹ç™½è³ªï¼šç´„ xxx g  
è„‚è‚ªï¼šç´„ xxx g  
ç¢³æ°´åŒ–åˆç‰©ï¼šç´„ xxx g`,
        },
      ],
    });


    const aiReply = completion.choices[0].message.content.trim();

    return lineClient.replyMessage(event.replyToken, {
      type: 'text',
      text: aiReply,
    });
  } catch (error) {
    console.error('ğŸ”´ ChatGPT å›è¦†éŒ¯èª¤ï¼š', error.status, error.message);
    return lineClient.replyMessage(event.replyToken, {
      type: 'text',
      text: 'âŒ æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚ç„¡æ³•å–å¾—è³‡æ–™ï¼Œè«‹ç¨å¾Œå†è©¦ï¼',
    });
  }
}

app.listen(port, () => {
  console.log(`ğŸš€ Server running on port ${port}`);
});
